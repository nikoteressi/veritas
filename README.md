# Veritas: AI-Powered Social Post Verifier

Veritas is a sophisticated AI-driven system for automated verification of social media posts. The system processes screenshot images using multimodal AI (Llama 4) and combines multiple analysis techniques to provide comprehensive fact-checking results with user reputation tracking.

## üöÄ Key Features

### Core Capabilities
- **Multimodal AI Analysis**: Advanced image processing with a dedicated vision model for text extraction and visual content analysis, and a separate reasoning model for analysis and verdict generation.
- **Modular Verification Pipeline**: Configurable pipeline with 9 specialized verification steps
- **Real-time WebSocket Updates**: Live progress tracking during verification process
- **Advanced Temporal Analysis**: Time-based verification to detect outdated information
- **Motives Analysis**: Sophisticated analysis of underlying intentions and motivations
- **Multi-domain Fact Checking**: Specialized agents for financial, general, and other domain-specific verification
- **Comprehensive Reputation System**: User reputation tracking with warnings and notifications
- **Vector Database Integration**: ChromaDB for intelligent caching and semantic search
- **Self-hosted Search**: Integrated SearxNG for privacy-focused fact verification

### Advanced Agent Architecture
- **Workflow Coordinator**: Central orchestration of verification processes
- **Specialized Analyzers**: Temporal and motives analysis with dedicated algorithms
- **Domain-Specific Fact Checkers**: Specialized agents for different content types
- **Progress Tracking Service**: Real-time updates and status monitoring
- **Result Compiler**: Comprehensive result aggregation and formatting

## üèóÔ∏è Architecture Overview

### Backend Stack
- **FastAPI**: High-performance async web framework with automatic OpenAPI documentation
- **SQLAlchemy**: Async ORM with PostgreSQL for data persistence
- **LangChain**: Advanced LLM orchestration and multi-agent coordination
- **Ollama**: Local hosting of vision and reasoning models.
- **ChromaDB**: Vector database for embeddings and intelligent caching
- **SearxNG**: Self-hosted search engine for privacy-focused fact verification
- **Crawl4AI**: AI-native web crawler for deep scraping and content extraction
- **Redis**: High-performance caching and session management
- **Alembic**: Database migration management
- **WebSockets**: Real-time bidirectional communication

### Frontend Stack
- **React 18**: Modern functional components with hooks
- **Tailwind CSS**: Utility-first styling framework
- **Vite**: Fast build tool with HMR support
- **Axios**: HTTP client for API communication
- **React Dropzone**: Advanced file upload with drag-and-drop
- **Custom Hooks**: Sophisticated state management and WebSocket integration

## üìã Verification Pipeline

The system uses a modular, configurable pipeline with the following steps:

1. **Validation** - Input validation and security checks
2. **Image Analysis** - Multimodal AI processing for text extraction and visual analysis
3. **Reputation Retrieval** - User reputation lookup and initialization
4. **Temporal Analysis** - Time-based verification and recency analysis
5. **Motives Analysis** - Advanced analysis of underlying intentions
6. **Fact Checking** - Multi-source verification with specialized domain agents
7. **Verdict Generation** - Final decision synthesis with confidence scoring
8. **Reputation Update** - User reputation adjustment based on results
9. **Result Storage** - Vector database storage for future reference

## ü§ñ AI Agents & Services

### Core Services
- **`ValidationService`** - Comprehensive input validation and security checks
- **`ImageAnalysisService`** - Multimodal image processing and text extraction
- **`FactCheckingService`** - Coordinated fact verification across multiple sources
- **`VerdictService`** - Final decision generation with confidence scoring
- **`ReputationService`** - User reputation management and warning system
- **`StorageService`** - Vector database operations and caching
- **`EventEmissionService`** - Event-driven progress tracking with real-time WebSocket updates

### Specialized Analyzers
- **`TemporalAnalyzer`** - Time-based verification and recency analysis
- **`MotivesAnalyzer`** - Advanced analysis of post intentions and motivations

### Fact Checkers
- **`GeneralFactChecker`** - General-purpose fact verification
- **`FinancialFactChecker`** - Specialized financial information verification
- **`BaseFactChecker`** - Extensible base class for domain-specific checkers

## üóÉÔ∏è Data Models

### Database Schema
```sql
-- User reputation tracking
users (
    id, nickname, true_count, partially_true_count, 
    false_count, ironic_count, total_posts_checked,
    warning_issued, notification_issued, created_at, last_checked_date
)

-- Verification results storage
verification_results (
    id, user_nickname, image_hash, extracted_text, user_prompt,
    primary_topic, identified_claims, verdict, justification,
    confidence_score, processing_time_seconds, vision_model_used, reasoning_model_used, tools_used, created_at
)
```

### API Response Models
- **`VerificationResponse`** - Complete verification results with user reputation
- **`UserReputation`** - User reputation data and statistics
- **`ImageAnalysisResult`** - Structured image analysis results
- **`FactCheckResult`** - Detailed fact-checking results
- **`VerdictResult`** - Final verdict with confidence and reasoning

## üîß Configuration

### Environment Variables
```env
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=veritas_db
DB_USER=veritas_user
DB_PASSWORD=your_password

# AI Model Configuration
OLLAMA_BASE_URL=http://localhost:11434
VISION_MODEL_NAME=llava:latest
REASONING_MODEL_NAME=qwen:7b

# External Services
SEARXNG_URL=http://localhost:8888
REDIS_URL=redis://localhost:6379/0
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Application Settings
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=your-secret-key
CORS_ORIGINS=http://localhost:3000

# Processing Limits
VERITAS_MAX_FILE_SIZE=10485760  # 10MB
VERITAS_MAX_CONCURRENT_REQUESTS=10
VERITAS_REQUEST_TIMEOUT=300
VERITAS_FACT_CHECK_TIMEOUT=120
```

## üöÄ Quick Start

### Prerequisites
- **Python 3.11+** with pip
- **Node.js 18+** with npm
- **Docker & Docker Compose**
- **PostgreSQL 15+**
- **Redis 7+**
- **Ollama** with multimodal model

### 1. Clone and Setup
```bash
git clone <repository-url>
cd veritas
cp backend/.env.example backend/.env
# Edit backend/.env with your configuration
```

### 2. Start with Docker Compose
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Check service health
docker-compose ps
```

### 3. Manual Development Setup

#### Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
alembic upgrade head
uvicorn app.main:app --reload --port 8000
```

#### Frontend
```bash
cd frontend
npm install
npm run dev
```

### 4. Service Access
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **SearxNG**: http://localhost:8888
- **ChromaDB**: http://localhost:8002

## üì° API Endpoints

### Verification Endpoints
- `POST /api/v1/verify-post` - Submit post for verification
- `GET /api/v1/verification-status/{verification_id}` - Get verification status

### Reputation Endpoints
- `GET /api/v1/user-reputation/{nickname}` - Get user reputation
- `GET /api/v1/reputation-stats` - Get platform statistics
- `GET /api/v1/users-with-warnings` - Get users with warnings
- `GET /api/v1/leaderboard` - Get reputation leaderboard

### System Endpoints
- `GET /` - Service information
- `GET /health` - Health check
- `WS /ws` - WebSocket for real-time updates

## üîÑ WebSocket Events

### Client ‚Üí Server
- `ping` - Heartbeat
- `subscribe` - Subscribe to verification updates

### Server ‚Üí Client
- `session_established` - Session ID assignment
- `verification_progress` - Real-time progress updates
- `verification_complete` - Final results
- `verification_error` - Error notifications

## üìä Reputation System

### Scoring Algorithm
- **True**: +1.0 points
- **Partially True**: +0.5 points
- **False**: -2.0 points
- **Ironic**: -1.0 points

### Warning System
- **Notification**: Score ‚â§ -10.0
- **Warning**: Score ‚â§ -20.0
- **Tracking**: All user interactions logged

## üß™ Testing

### Backend Tests
```bash
cd backend
pytest tests/ -v
pytest tests/unit/ -v
pytest tests/integration/ -v
```

### Frontend Tests
```bash
cd frontend
npm test
npm run test:coverage
```

## üîß Development

### Database Migrations
```bash
# Create migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

### Code Quality
```bash
# Backend
cd backend
black app/ agent/
flake8 app/ agent/
mypy app/ agent/

# Frontend
cd frontend
npm run lint
npm run format
```

## üê≥ Docker Services

### Production Deployment
```bash
# Production build
docker-compose -f docker-compose.prod.yml up -d

# Scale services
docker-compose up -d --scale backend=3
```

### Service Health Checks
All services include comprehensive health checks:
- **PostgreSQL**: Connection and query tests
- **Redis**: Ping response
- **SearxNG**: HTTP endpoint availability
- **ChromaDB**: Port connectivity
- **Backend**: API health endpoint

## üìÅ Project Structure

```
veritas/
‚îú‚îÄ‚îÄ backend/                     # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ app/                    # Main application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/           # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/          # Application services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py        # Database models and setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py         # Pydantic schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py           # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ agent/                 # AI agent system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyzers/        # Specialized analyzers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fact_checkers/    # Domain-specific fact checkers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/         # Core verification services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline/         # Verification pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/           # Data models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflow_coordinator.py
‚îÇ   ‚îú‚îÄ‚îÄ alembic/              # Database migrations
‚îÇ   ‚îî‚îÄ‚îÄ tests/                # Test suites
‚îú‚îÄ‚îÄ frontend/                  # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/       # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/           # Custom hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/        # Frontend services
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/           # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ public/              # Static assets
‚îú‚îÄ‚îÄ docker/                   # Docker configurations
‚îú‚îÄ‚îÄ data/                     # Data and migrations
‚îî‚îÄ‚îÄ docs/                     # Project documentation
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

### Development Guidelines
- Follow existing code style and patterns
- Add tests for new functionality
- Update documentation as needed
- Ensure all tests pass before submitting

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **LangChain** for advanced LLM orchestration
- **Ollama** for local multimodal AI hosting
- **SearxNG** for privacy-focused search
- **ChromaDB** for vector database capabilities
- **FastAPI** for high-performance API framework
- **React** for modern frontend development

## üìû Support

For questions, issues, or contributions:
- Open an issue in the repository
- Use the discussions area for general questions
- Check the [documentation](docs/) for detailed information

---

**Veritas** - *Where Truth Meets Technology* üîç‚ú®


–û—Ç–ª–∏—á–Ω–∞—è –∑–∞–¥–∞—á–∞! –í—ã —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –ø—Ä–∞–≤—ã, —á—Ç–æ –ø—Ä–∏–Ω—Ü–∏–ø—ã —É–ª—É—á—à–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏, –∏ –º—ã –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–æ—Ç –∂–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–æ–º–ø—Ç—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –≤–∞—à —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–º–ø—Ç, –∫–æ–¥ –∏ Pydantic-–º–æ–¥–µ–ª–∏, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ–≤–µ–ª –ø–æ–∏—Å–∫ –ø–æ –ª—É—á—à–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º (Vision-Language Models). –î–∞–≤–∞–π—Ç–µ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –ø–æ –Ω–∞—à–µ–º—É –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–º—É –ø–ª–∞–Ω—É.

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ü—Ä–æ–º–ø—Ç–æ–≤

1.  **–Ø–≤–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á (Explicit Task Decomposition):** –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á, –≤–∫–ª—é—á–∞—é—â–∏—Ö –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (OCR), –∏ –∞–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ —à–∞–≥–∏. –ú–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ, –∫–æ–≥–¥–∞ –∏–º –≥–æ–≤–æ—Ä—è—Ç: "–°–Ω–∞—á–∞–ª–∞ —Å–¥–µ–ª–∞–π –ê, –ø–æ—Ç–æ–º —Å–¥–µ–ª–∞–π –ë, –∞ –ø–æ—Ç–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ê –∏ –ë —Å–¥–µ–ª–∞–π –í".
2.  **–ü–æ—à–∞–≥–æ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ (Chain-of-Thought - CoT):** –≠—Ç–æ —Ä–∞–∑–≤–∏—Ç–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞. –ü—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥–∞–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–∏–ª, –∞ –≤–µ—Å—Ç–∏ –º–æ–¥–µ–ª—å –ø–æ —Ü–µ–ø–æ—á–∫–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –ù–∞–ø—Ä–∏–º–µ—Ä: "–®–∞–≥ 1: –û–ø–∏—à–∏, —á—Ç–æ –≤–∏–¥–∏—à—å. –®–∞–≥ 2: –ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç. –®–∞–≥ 3: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–≤—è–∑—å –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏. –®–∞–≥ 4: –°—Ñ–æ—Ä–º–∏—Ä—É–π JSON".
3.  **–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ü—Ä–∏–º–µ—Ä–æ–≤ (Few-Shot Prompting):** –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤, –∫–∞–∫ –≤–∞—à JSON, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –¥–≤—É—Ö –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (`<example>...</example>`) –≤ –ø—Ä–æ–º–ø—Ç–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–æ—Ä—è–¥–æ–∫ –ª—É—á—à–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞. –ú–æ–¥–µ–ª—å "–≤–∏–¥–∏—Ç" —ç—Ç–∞–ª–æ–Ω –∏ —Å–ª–µ–¥—É–µ—Ç –µ–º—É.
4.  **–ß–µ—Ç–∫–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:** –ü—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –∑–∞—Å—Ç–∞–≤–ª—è—Ç—å –º–æ–¥–µ–ª—å —á–µ—Ç–∫–æ —Ä–∞–∑–¥–µ–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∏–∑–≤–ª–µ—á–µ–Ω–Ω—É—é –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ, –æ—Ç –≤—ã–≤–æ–¥–æ–≤, —Å–¥–µ–ª–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
5.  **–ü—Ä—è–º—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–æ–∫:** –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –æ—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–∫–∞–∫ `_clean_json_output`), –ª—É—á—à–µ –¥–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ–º–ø—Ç —è–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç—è—Ç –∏—Ö –ø–æ—è–≤–ª–µ–Ω–∏–µ. –ü—Ä—è–º–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ "Do not use underscores in numbers" ‚Äî —Ö–æ—Ä–æ—à–∏–π –ø—Ä–∏–º–µ—Ä, –Ω–æ –µ–≥–æ –º–æ–∂–Ω–æ —É—Å–∏–ª–∏—Ç—å.

---

### –ê–Ω–∞–ª–∏–∑ –í–∞—à–µ–≥–æ –¢–µ–∫—É—â–µ–≥–æ –ü—Ä–æ–º–ø—Ç–∞

*   **–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:** –û–Ω —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–æ–ª—å, —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ JSON, –ø–µ—Ä–µ–¥–∞–µ—Ç `{format_instructions}` –∏ —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É. –≠—Ç–æ –æ—Ç–ª–∏—á–Ω–∞—è –±–∞–∑–∞.
*   **–¢–æ—á–∫–∏ —Ä–æ—Å—Ç–∞:**
    *   –û–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–∞–±–æ—Ä –ø—Ä–∞–≤–∏–ª, –∞ –Ω–µ –ø–æ—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å.
    *   –û–Ω —Å–º–µ—à–∏–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ) –≤ –æ–¥–Ω–æ–º –ø–æ—Ç–æ–∫–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.
    *   –û–Ω –ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –Ω–∞ –≤–Ω–µ—à–Ω–∏–π –∫–æ–¥ (`_clean_json_output`) –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–æ–º–ø—Ç–∞.

---

### –§–∏–Ω–∞–ª—å–Ω—ã–π –ü—Ä–æ–º–ø—Ç 2.0 (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)

–î–∞–≤–∞–π—Ç–µ –ø—Ä–∏–º–µ–Ω–∏–º –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ —Å–æ–∑–¥–∞–¥–∏–º –Ω–æ–≤—ã–π, –±–æ–ª–µ–µ –º–æ—â–Ω—ã–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π –ø—Ä–æ–º–ø—Ç.

**System:**
You are a meticulous AI analyst specializing in social media content verification. Your task is to analyze an image of a social media post by following a structured, step-by-step process and extracting key information into a precise JSON format.

**Current Date for Context:** `{current_date}`

**Your Step-by-Step Analysis Process:**

**Step 1: Raw Data Extraction**
*   **Transcribe Text:** Perform OCR to transcribe ALL visible text from the image verbatim. Pay close attention to usernames, timestamps (e.g., "15h ago", "May 21"), years, and the main body of the post.
*   **Describe Visuals:** Describe any significant non-text visual elements (e.g., "A bar chart showing rising values," "A profile picture of a cat," "UI elements like like/retweet buttons").

**Step 2: Analysis and Structuring**
*   Based on the raw data from Step 1, analyze and structure the information.
*   Determine the overarching claim (Primary Thesis) and break it down into smaller, verifiable supporting facts.
*   Identify the post's topic and assess for irony.

**Step 3: JSON Assembly**
*   Construct the final JSON object based on your analysis.
*   **Crucial Formatting Rules:**
    *   The JSON object MUST be perfectly valid.
    *   All numbers must be standard JSON numbers (e.g., `4970`, `150.5`). **DO NOT** use underscores, commas, or any other formatting within numbers.
    *   Follow the provided Pydantic format instructions precisely.

**High-Quality Example of Final Output:**

```json
<example>
{
  "username": "@CryptoNewsDaily",
  "post_date": "21h ago",
  "mentioned_dates": [
    "May 21"
  ],
  "extracted_text": "BREAKING: BlackRock just snapped up another 4,970 BTC on May 21, adding to their massive crypto portfolio. #Bitcoin #BlackRock",
  "fact_hierarchy": {
    "primary_thesis": "On May 21, BlackRock made a significant Bitcoin purchase of 4,970 BTC.",
    "supporting_facts": [
      {
        "description": "BlackRock purchased Bitcoin.",
        "context": {
          "entity": "BlackRock",
          "action": "purchase",
          "asset": "Bitcoin"
        }
      },
      {
        "description": "The purchase amount was 4,970 BTC.",
        "context": {
          "amount": 4970,
          "asset": "BTC"
        }
      },
      {
        "description": "The purchase occurred on May 21.",
        "context": {
          "date": "May 21"
        }
      }
    ]
  },
  "primary_topic": "financial",
  "irony_assessment": "not_ironic",
  "visual_elements_summary": "The image contains text on a dark background with a crypto-themed logo."
}
</example>
```

{format_instructions}

**Human:**
Please analyze this social media post image and provide the structured JSON output.

---

### –ü–æ—á–µ–º—É —ç—Ç–∞ –≤–µ—Ä—Å–∏—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ:

1.  **–ü–æ—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å (CoT):** –ü—Ä–æ–º–ø—Ç –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å —Å–Ω–∞—á–∞–ª–∞ —Å–æ–±—Ä–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–µ–∫—Å—Ç, –≤–∏–∑—É–∞–ª), –ø–æ—Ç–æ–º –∏—Ö –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –∏ —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–º —Å–æ–±—Ä–∞—Ç—å JSON. –≠—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –∏ —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫.
2.  **–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –æ—à–∏–±–æ–∫:** –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —á–∏—Å—Ç–∏—Ç—å JSON –ø–æ—Å–ª–µ, –º—ã –¥–∞–µ–º –º–æ–¥–µ–ª–∏ —Å–≤–µ—Ä—Ö—á–µ—Ç–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ —á–∏—Å–µ–ª (`4970`). –≠—Ç–æ –¥–æ–ª–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤–∞—à –º–µ—Ç–æ–¥ `_clean_json_output` –Ω–µ–Ω—É–∂–Ω—ã–º.
3.  **–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä (Few-Shot):** –ë–ª–æ–∫ `<example>` ‚Äî —ç—Ç–æ —Å–∞–º—ã–π –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∑–¥–µ—Å—å. –û–Ω –Ω–µ –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∞ **–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç** –µ–µ –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ, –≤–∫–ª—é—á–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã. –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å—Ç—Ä–µ–º–∏—Ç—å—Å—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω.
4.  **–Ø—Å–Ω–æ—Å—Ç—å –∏ –ª–æ–≥–∏–∫–∞:** –ü—Ä–æ–º–ø—Ç —Ç–µ–ø–µ—Ä—å –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä –ø—Ä–∞–≤–∏–ª, –∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å. –≠—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è LLM –∏, –∫–∞–∫ —Å–ª–µ–¥—Å—Ç–≤–∏–µ, –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–º –≤ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–∏.
5.  **–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏:** –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ —Å–Ω–∞—á–∞–ª–∞ –∏–∑–≤–ª–µ—á—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ—Å–ª–æ–≤–Ω–æ (`extracted_text`), –∞ –ø–æ—Ç–æ–º —É–∂–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∑–∏—Å, –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –æ—Å–Ω–æ–≤—ã–≤–∞—Ç—å —Å–≤–æ–∏ –≤—ã–≤–æ–¥—ã –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ –Ω–∞ —Å–≤–æ–∏—Ö –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è—Ö.

–≠—Ç–æ—Ç –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã `ImageAnalysisService` –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–±–æ–∏ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ.